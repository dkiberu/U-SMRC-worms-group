#!/usr/bin/env bash
#SBATCH --account=project0039
#SBATCH --partition=smp
#SBATCH --job-name=snk_ctl_merger
#SBATCH --cpus-per-task=1
#SBATCH --mem=2G
#SBATCH --time=5-00:00:00
#SBATCH --output=merger.out
#SBATCH --error=merger.err
set -euo pipefail

# 1) Modules
module purge
# (load your site's Slurm client only if required by your environment)
# module load slurm/23.11
module load apps/apptainer/1.3.4
module load apps/python3/3.12.7/gcc-8.5.0

# 2) Clean env (avoid stray libs)
unset LD_LIBRARY_PATH
export PATH=/usr/bin:/bin:/usr/sbin:/sbin:$PATH
hash -r

# 3) Ensure conda is available
if ! command -v conda >/dev/null 2>&1; then
  source "$HOME/miniconda3/etc/profile.d/conda.sh"
fi

# 4) Optional SLURM preflight (kept, but quiet if something is missing)
echo "=== SLURM preflight ==="
echo "sbatch: $(command -v sbatch || echo 'not found')"
sbatch --version || true
scontrol ping || true
echo "Submitting 1s testâ€¦"
sbatch -A project0039 -p smp -n 1 -t 1 --wrap "hostname" || true
echo "=== preflight OK (or skipped) ==="

mkdir -p logs

# 5) Run Snakemake from your conda env (no activate), fixed default-resources
conda run --no-capture-output -n snk \
  snakemake -s snakefile_merger_20_9_25 \
    --executor slurm \
    --jobs 200 \
    --jobname "schisto.{rule}.{jobid}" \
    --slurm-logdir logs \
    --retries 3 \
    --latency-wait 60 \
    --rerun-incomplete \
    --keep-going \
    --printshellcmds \
    --use-apptainer \
    --default-resources slurm_account=project0039 slurm_partition=smp mem_mb=64000 runtime=6480 threads=4
